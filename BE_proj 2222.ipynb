{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00      1986\n",
      "           Y       0.88      0.58      0.70        12\n",
      "\n",
      "    accuracy                           1.00      1998\n",
      "   macro avg       0.94      0.79      0.85      1998\n",
      "weighted avg       1.00      1.00      1.00      1998\n",
      "\n",
      "[[1985    1]\n",
      " [   5    7]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"DATA1.csv\")\n",
    "x=data[['koi_score','koi_period','koi_ror','koi_srho','koi_prad','koi_sma','koi_teq','koi_insol','koi_dor','koi_count','koi_steff','koi_slogg','koi_smet','koi_srad','koi_smass']]\n",
    "y=data['O/P']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,random_state=2)\n",
    "len(X_train)\n",
    "lr = LogisticRegression(max_iter = 100000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9929078014184397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2371\n",
      "           Y       0.80      0.46      0.59        26\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.90      0.73      0.79      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2368    3]\n",
      " [  14   12]]\n",
      "0.9933249895702962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2371\n",
      "           Y       0.92      0.42      0.58        26\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.96      0.71      0.79      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2370    1]\n",
      " [  15   11]]\n",
      "0.9924906132665833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2371\n",
      "           Y       0.83      0.38      0.53        26\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.91      0.69      0.76      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2369    2]\n",
      " [  16   10]]\n",
      "0.9908218606591572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2370\n",
      "           Y       0.78      0.26      0.39        27\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.88      0.63      0.69      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2368    2]\n",
      " [  20    7]]\n",
      "0.9924906132665833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2372\n",
      "           Y       0.68      0.52      0.59        25\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.84      0.76      0.79      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2366    6]\n",
      " [  12   13]]\n",
      "0.9941593658740092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2373\n",
      "           Y       0.92      0.46      0.61        24\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.96      0.73      0.80      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2372    1]\n",
      " [  13   11]]\n",
      "0.9908218606591572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2370\n",
      "           Y       0.65      0.41      0.50        27\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.82      0.70      0.75      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2364    6]\n",
      " [  16   11]]\n",
      "0.9908218606591572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2376\n",
      "           Y       0.47      0.38      0.42        21\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.73      0.69      0.71      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2367    9]\n",
      " [  13    8]]\n",
      "0.9941593658740092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      1.00      1.00      2374\n",
      "           Y       0.85      0.48      0.61        23\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.92      0.74      0.80      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2372    2]\n",
      " [  12   11]]\n",
      "0.9962453066332916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00      2378\n",
      "           Y       0.86      0.63      0.73        19\n",
      "\n",
      "    accuracy                           1.00      2397\n",
      "   macro avg       0.93      0.82      0.86      2397\n",
      "weighted avg       1.00      1.00      1.00      2397\n",
      "\n",
      "[[2376    2]\n",
      " [   7   12]]\n",
      "0.9928243637880685\n"
     ]
    }
   ],
   "source": [
    "accuracy_model = []\n",
    "smt = SMOTE()\n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    X_train_S, y_train_S = smt.fit_sample(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model.append(accuracy_score(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "print(np.mean(accuracy_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.98      2378\n",
      "           Y       0.20      0.95      0.33        19\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.60      0.96      0.66      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "[[2307   71]\n",
      " [   1   18]]\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTE()\n",
    "X_train_S, y_train_S = smt.fit_sample(X_train, y_train,)\n",
    "lr = LogisticRegression(max_iter = 100000)\n",
    "lr.fit(X_train_S, y_train_S)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787234042553191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.98      0.99      2374\n",
      "           Y       0.29      0.87      0.44        23\n",
      "\n",
      "    accuracy                           0.98      2397\n",
      "   macro avg       0.65      0.92      0.71      2397\n",
      "weighted avg       0.99      0.98      0.98      2397\n",
      "\n",
      "0.9816437213183146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.98      0.99      2374\n",
      "           Y       0.32      0.83      0.46        23\n",
      "\n",
      "    accuracy                           0.98      2397\n",
      "   macro avg       0.66      0.90      0.73      2397\n",
      "weighted avg       0.99      0.98      0.99      2397\n",
      "\n",
      "0.9712140175219024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.99      2366\n",
      "           Y       0.31      0.97      0.47        31\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.65      0.97      0.73      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9732999582811848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.99      2373\n",
      "           Y       0.27      0.96      0.42        24\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.63      0.97      0.70      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9691280767626199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.98      2374\n",
      "           Y       0.21      0.83      0.34        23\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.61      0.90      0.66      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9749687108886108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.98      0.99      2371\n",
      "           Y       0.30      0.96      0.45        26\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.65      0.97      0.72      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9695452649144765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.98      2376\n",
      "           Y       0.22      0.95      0.35        21\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.61      0.96      0.67      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9645390070921985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.96      0.98      2378\n",
      "           Y       0.18      0.95      0.30        19\n",
      "\n",
      "    accuracy                           0.96      2397\n",
      "   macro avg       0.59      0.96      0.64      2397\n",
      "weighted avg       0.99      0.96      0.98      2397\n",
      "\n",
      "0.968293700458907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.98      2372\n",
      "           Y       0.24      0.96      0.39        25\n",
      "\n",
      "    accuracy                           0.97      2397\n",
      "   macro avg       0.62      0.96      0.69      2397\n",
      "weighted avg       0.99      0.97      0.98      2397\n",
      "\n",
      "0.9628702544847726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.96      0.98      2380\n",
      "           Y       0.15      0.94      0.26        17\n",
      "\n",
      "    accuracy                           0.96      2397\n",
      "   macro avg       0.58      0.95      0.62      2397\n",
      "weighted avg       0.99      0.96      0.98      2397\n",
      "\n",
      "0.9714226115978306\n"
     ]
    }
   ],
   "source": [
    "accuracy_model = []\n",
    "kf = KFold(n_splits=10)\n",
    "for train, test in kf.split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    X_train_S, y_train_S = smt.fit_sample(X_train, y_train)\n",
    "    lr.fit(X_train_S, y_train_S)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model.append(accuracy_score(y_test,y_pred))\n",
    "print(np.mean(accuracy_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541927409261577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.54      0.70      2380\n",
      "           Y       0.02      1.00      0.03        17\n",
      "\n",
      "    accuracy                           0.54      2397\n",
      "   macro avg       0.51      0.77      0.37      2397\n",
      "weighted avg       0.99      0.54      0.70      2397\n",
      "\n",
      "[[1282 1098]\n",
      " [   0   17]]\n"
     ]
    }
   ],
   "source": [
    "X_train_S, y_train_S = smt.fit_sample(X_train, y_train,)\n",
    "clf = svm.SVC(kernel = 'rbf')\n",
    "clf.fit(X_train_S, y_train_S)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6962870254484773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.69      0.82      2373\n",
      "           Y       0.03      1.00      0.06        24\n",
      "\n",
      "    accuracy                           0.70      2397\n",
      "   macro avg       0.52      0.85      0.44      2397\n",
      "weighted avg       0.99      0.70      0.81      2397\n",
      "\n",
      "0.672924488944514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.67      0.80      2369\n",
      "           Y       0.03      0.96      0.06        28\n",
      "\n",
      "    accuracy                           0.67      2397\n",
      "   macro avg       0.52      0.82      0.43      2397\n",
      "weighted avg       0.99      0.67      0.79      2397\n",
      "\n",
      "0.803087192323738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.80      0.89      2375\n",
      "           Y       0.04      1.00      0.09        22\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.52      0.90      0.49      2397\n",
      "weighted avg       0.99      0.80      0.88      2397\n",
      "\n",
      "0.5677930746766792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.56      0.72      2374\n",
      "           Y       0.02      1.00      0.04        23\n",
      "\n",
      "    accuracy                           0.57      2397\n",
      "   macro avg       0.51      0.78      0.38      2397\n",
      "weighted avg       0.99      0.57      0.71      2397\n",
      "\n",
      "0.7626199415936588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.76      0.86      2376\n",
      "           Y       0.03      0.95      0.07        21\n",
      "\n",
      "    accuracy                           0.76      2397\n",
      "   macro avg       0.52      0.86      0.46      2397\n",
      "weighted avg       0.99      0.76      0.86      2397\n",
      "\n",
      "0.7768043387567793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.78      0.87      2376\n",
      "           Y       0.03      0.81      0.06        21\n",
      "\n",
      "    accuracy                           0.78      2397\n",
      "   macro avg       0.51      0.79      0.47      2397\n",
      "weighted avg       0.99      0.78      0.87      2397\n",
      "\n",
      "0.8210262828535669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.82      0.90      2374\n",
      "           Y       0.05      0.96      0.09        23\n",
      "\n",
      "    accuracy                           0.82      2397\n",
      "   macro avg       0.52      0.89      0.50      2397\n",
      "weighted avg       0.99      0.82      0.89      2397\n",
      "\n",
      "0.754276178556529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.75      0.86      2376\n",
      "           Y       0.03      0.81      0.05        21\n",
      "\n",
      "    accuracy                           0.75      2397\n",
      "   macro avg       0.51      0.78      0.46      2397\n",
      "weighted avg       0.99      0.75      0.85      2397\n",
      "\n",
      "0.670421360033375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.67      0.80      2376\n",
      "           Y       0.03      1.00      0.05        21\n",
      "\n",
      "    accuracy                           0.67      2397\n",
      "   macro avg       0.51      0.83      0.43      2397\n",
      "weighted avg       0.99      0.67      0.79      2397\n",
      "\n",
      "0.8719232373800584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.87      0.93      2380\n",
      "           Y       0.04      0.76      0.08        17\n",
      "\n",
      "    accuracy                           0.87      2397\n",
      "   macro avg       0.52      0.82      0.50      2397\n",
      "weighted avg       0.99      0.87      0.93      2397\n",
      "\n",
      "0.7397163120567376\n"
     ]
    }
   ],
   "source": [
    "accuracy_model_2 = []\n",
    "for train, test in kf.split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    X_train_S, y_train_S = smt.fit_sample(X_train, y_train)\n",
    "    clf.fit(X_train_S, y_train_S)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model_2.append(accuracy_score(y_test,y_pred))\n",
    "print(np.mean(accuracy_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920734251147267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2380\n",
      "           Y       0.46      0.76      0.58        17\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.73      0.88      0.79      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "[[2365   15]\n",
      " [   4   13]]\n"
     ]
    }
   ],
   "source": [
    "X_train_S, y_train_S = smt.fit_sample(X_train, y_train,)\n",
    "RF = RandomForestClassifier(n_estimators = 100, min_samples_leaf = 2,min_samples_split = 10, max_depth = 100) \n",
    "RF.fit(X_train_S, y_train_S)\n",
    "y_pred = RF.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920734251147267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2372\n",
      "           Y       0.59      0.76      0.67        25\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.80      0.88      0.83      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9920734251147267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2376\n",
      "           Y       0.53      0.81      0.64        21\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.76      0.90      0.82      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9904046725073008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2371\n",
      "           Y       0.55      0.62      0.58        26\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.77      0.80      0.79      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9941593658740092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00      2380\n",
      "           Y       0.56      0.82      0.67        17\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.78      0.91      0.83      2397\n",
      "weighted avg       1.00      0.99      0.99      2397\n",
      "\n",
      "0.9912390488110138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2373\n",
      "           Y       0.55      0.67      0.60        24\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.77      0.83      0.80      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9937421777221527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2381\n",
      "           Y       0.52      0.81      0.63        16\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.76      0.90      0.82      2397\n",
      "weighted avg       1.00      0.99      0.99      2397\n",
      "\n",
      "0.9899874843554443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99      2377\n",
      "           Y       0.44      0.75      0.56        20\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.72      0.87      0.78      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9924906132665833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2380\n",
      "           Y       0.48      0.71      0.57        17\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.74      0.85      0.78      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9941593658740092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00      2378\n",
      "           Y       0.62      0.68      0.65        19\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.81      0.84      0.82      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9916562369628703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      1.00      2378\n",
      "           Y       0.48      0.84      0.62        19\n",
      "\n",
      "    accuracy                           0.99      2397\n",
      "   macro avg       0.74      0.92      0.81      2397\n",
      "weighted avg       0.99      0.99      0.99      2397\n",
      "\n",
      "0.9921985815602836\n"
     ]
    }
   ],
   "source": [
    "accuracy_model_3 = []\n",
    "for train, test in kf.split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    X_train_S, y_train_S = smt.fit_sample(X_train, y_train)\n",
    "    RF.fit(X_train_S, y_train_S)\n",
    "    y_pred = RF.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model_3.append(accuracy_score(y_test,y_pred))\n",
    "print(np.mean(accuracy_model_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8639966624947851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.86      0.93      2378\n",
      "           Y       0.05      0.89      0.09        19\n",
      "\n",
      "    accuracy                           0.86      2397\n",
      "   macro avg       0.52      0.88      0.51      2397\n",
      "weighted avg       0.99      0.86      0.92      2397\n",
      "\n",
      "[[2054  324]\n",
      " [   2   17]]\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_test_minmax = min_max_scaler.fit_transform(X_test)\n",
    "gnb = ComplementNB()\n",
    "gnb.fit(X_train_minmax, y_train)\n",
    "y_pred = gnb.predict(X_test_minmax)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-43d8f535c541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_train_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"true\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_minmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_minmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;34m\"\"\"Count feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ComplementNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "accuracy_model_4 = []\n",
    "for train, test in kf.split(data):\n",
    "    X_train_minmax, X_test_minmax, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    gnb.fit(X_train_minmax, y_train)\n",
    "    y_pred = gnb.predict(X_test_minmax)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model_4.append(accuracy_score(y_test,y_pred))\n",
    "print(np.mean(accuracy_model_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701293283270755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.77      0.87      2379\n",
      "           Y       0.01      0.22      0.01        18\n",
      "\n",
      "    accuracy                           0.77      2397\n",
      "   macro avg       0.50      0.50      0.44      2397\n",
      "weighted avg       0.99      0.77      0.86      2397\n",
      "\n",
      "[[1842  537]\n",
      " [  14    4]]\n",
      "0.7701293283270755\n"
     ]
    }
   ],
   "source": [
    "X_train_S, y_train_S = smt.fit_sample(X_train, y_train,)\n",
    "N = KNeighborsClassifier(n_neighbors=6)\n",
    "N.fit(X_train_S, y_train_S)\n",
    "y_pred = N.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(f1_score(y_test,y_pred,average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8135168961201502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2372\n",
      "           Y       0.00      0.04      0.00        25\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.43      0.45      2397\n",
      "weighted avg       0.98      0.81      0.89      2397\n",
      "\n",
      "0.8114309553608677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2373\n",
      "           Y       0.01      0.17      0.02        24\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.49      0.46      2397\n",
      "weighted avg       0.98      0.81      0.89      2397\n",
      "\n",
      "0.8130997079682937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2374\n",
      "           Y       0.01      0.13      0.01        23\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.48      0.45      2397\n",
      "weighted avg       0.98      0.81      0.89      2397\n",
      "\n",
      "0.8181059657905716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2378\n",
      "           Y       0.00      0.11      0.01        19\n",
      "\n",
      "    accuracy                           0.82      2397\n",
      "   macro avg       0.50      0.46      0.45      2397\n",
      "weighted avg       0.98      0.82      0.89      2397\n",
      "\n",
      "0.8143512724238632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2383\n",
      "           Y       0.00      0.14      0.01        14\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.48      0.45      2397\n",
      "weighted avg       0.99      0.81      0.89      2397\n",
      "\n",
      "0.8197747183979975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2382\n",
      "           Y       0.00      0.13      0.01        15\n",
      "\n",
      "    accuracy                           0.82      2397\n",
      "   macro avg       0.50      0.48      0.46      2397\n",
      "weighted avg       0.99      0.82      0.90      2397\n",
      "\n",
      "0.8010012515644556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.81      0.89      2373\n",
      "           Y       0.01      0.25      0.02        24\n",
      "\n",
      "    accuracy                           0.80      2397\n",
      "   macro avg       0.50      0.53      0.46      2397\n",
      "weighted avg       0.98      0.80      0.88      2397\n",
      "\n",
      "0.819357530246141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2377\n",
      "           Y       0.01      0.25      0.02        20\n",
      "\n",
      "    accuracy                           0.82      2397\n",
      "   macro avg       0.50      0.54      0.46      2397\n",
      "weighted avg       0.98      0.82      0.89      2397\n",
      "\n",
      "0.8085106382978723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.89      2374\n",
      "           Y       0.00      0.04      0.00        23\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.43      0.45      2397\n",
      "weighted avg       0.98      0.81      0.89      2397\n",
      "\n",
      "0.8105965790571548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.82      0.90      2377\n",
      "           Y       0.01      0.15      0.01        20\n",
      "\n",
      "    accuracy                           0.81      2397\n",
      "   macro avg       0.50      0.48      0.45      2397\n",
      "weighted avg       0.98      0.81      0.89      2397\n",
      "\n",
      "0.8129745515227368\n"
     ]
    }
   ],
   "source": [
    "accuracy_model_5 = []\n",
    "for train, test in kf.split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, shuffle = \"true\")\n",
    "    N = KNeighborsClassifier(n_neighbors=6)\n",
    "    N.fit(X_train_S, y_train_S)\n",
    "    y_pred = N.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    accuracy_model_5.append(accuracy_score(y_test,y_pred))\n",
    "print(np.mean(accuracy_model_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
